{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Ансамбли. Бэггинг и случайный лес"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "SEED = 314159\n",
    "TRAIN_TEST_SPLIT = 0.80\n",
    "\n",
    "data_path = \"D:\\data\\machine_learning\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Деревья решений имеют так называемый низкий предвзятость/сдвиг (bias) и высокую дисперсию (variance). В результате модели на их основе подвержены переобучению, но в целом достаточно точны. Это свойство деревьев решений активно эксплуатируется в ансамблях (где используются и другие модели, но чаще всего именно они)\n",
    "Рассмотрим разные способы ансамблирования."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Bagging\n",
    "Бэггинг (bootstrap aggregating) — это ансамблевый метод, который включает в себя независимое обучение нескольких моделей на случайных подмножествах данных и агрегирование их прогнозов посредством голосования или усреднения.\n",
    "\n",
    "С помощью бэггинга работают и случайные леса. Идея в том, чтобы последовательно получить выборку с возвращением n раз и обучить n базовых моделей $b_i(x) = b(x, X^i)$.\n",
    "Предсказание результрующей модели будут выглядеть как $a(x) = \\frac{1}{k}(b_1(x) + \\dots + b_k(x)).$\n",
    "\n",
    "Этапы построения ансамля:\n",
    "1) Создается бутстрапированная выборка\n",
    "2) На ней учится дерево решений\n",
    "3) Для финального предсказания используется среднее всех деревьев\n",
    "\n",
    "Вопрос: будет ли бэггинг подвержен оверфиттингу, как одно решающее дерево?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path+'/'+\"winequality-red.csv\")\n",
    "df_major = df[df[\"quality\"].isin([5,6])]\n",
    "print(\"Length of filtered data is\", len(df_major))\n",
    "X = df_major.drop('quality', axis=1)\n",
    "y = df_major['quality']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(random_state=SEED)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Train score is: \", model.score(X_train, y_train))\n",
    "print(\"Test score is: \", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Фактически мы можем вычислить, что вероятность того, что наблюдение будет исключено из нашего набора данных с бутсрапированием, равна $(1 - \\frac{1}{n})^{n}$.\n",
    "По определению $e^{-1} = \\displaystyle \\lim_{n\\to\\infty}(1-\\frac{1}{n})^n$ и так как $e^{-1} ~ 0.36$, то мы выкидываем примерно треть всех данных в каждом дереве. То есть получается, что каждое дерево, построенное на такой выборке, будет достаточно сильно отличаться от остальных. Будет ли этого достаточно для получения нескоррелированных моделей?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "X_train_bs, y_train_bs = # resamle data once or twice to check that final sample differs\n",
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Bagging\n",
    "Бэггинг — это процесс выращивания дерева, при котором каждый узел дерева просматривает каждый признак в нашей бутстрапированной выборке, чтобы найти наилучшее разделение данных в этом конкретном узле. Это повторяется для всех деревьев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "model = # create decision tree\n",
    "# Create a bagging classifier with the decision tree pipeline\n",
    "bagging_classifier = BaggingClassifier(estimator=model, n_estimators=50, random_state=42)\n",
    "\n",
    "# Train the bagging classifier on the training data\n",
    "bagging_classifier.fit(X_train, y_train)\n",
    "print(\"Train score is: \", bagging_classifier.score(X_train, y_train))\n",
    "print(\"Test score is: \", bagging_classifier.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "В бэггинге делается предположение, что базовые модели некоррелированы, и за счёт этого получается очень сильное уменьшение дисперсии у ансамбля относительно базовых моделей. Однако в реальной жизни добиться этого сложно: ведь базовые алгоритмы учили одну и ту же зависимость на пересекающихся выборках.\n",
    "На практике оказывается, что строгое выполнение этого предположения не обязательно. Достаточно, чтобы модели были в некоторой степени не похожи друг на друга. На этом облегчении строится развитие идеи бэггинга для решающих деревьев — случайный лес.\n",
    "\n",
    "Главное отличие случайного леса от bagging-а в том, что в случайном лесе рассматривается только $m=\\sqrt(p)$ признаков. Благодаря этому мы сможем создавать множество *некоррелированных* деревьев, которые помогут нам уловить большую часть изменчивости, а также взаимодействия между несколькими переменными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# fit and get scores for random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Для того, чтобы лучше понять, как устроен случайный лес, сделаем свою (упрощенную) версию этой модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "class RandomForest(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_estimators: int = 10, random_state: int = 0, max_features=\"sqrt\",**kwargs):\n",
    "        super().__init__()\n",
    "        self.max_features = max_features\n",
    "        # init forest\n",
    "        self._estimators = []\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if self.max_features == \"sqrt\":\n",
    "            # set max features as sqrt of number of features\n",
    "        elif self.max_features == \"log\":\n",
    "            # set max features as log2 of number of features\n",
    "        else:\n",
    "            self.max_features = None\n",
    "\n",
    "        for i in range(self.n_estimators):\n",
    "            # fit estimators\n",
    "\n",
    "    def predict(self, X):\n",
    "        predicts = []\n",
    "        # get predict from every estimator\n",
    "        predicts = np.array(predicts).T\n",
    "        predicts = np.array([np.argmax(np.bincount(predicts[i])) for i in range(len(X))])\n",
    "        return predicts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# fit your random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"Train score is: \", model.score(X_train, y_train))\n",
    "print(\"Test score is: \", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# OOB test\n",
    "Еще одна замечательная особенность бутсреппинга заключается в том, что мы бесплатно получаем так называемую out-of-bag оценку ошибок. Выборка OOB (out of bag) — это ≈1/3 наблюдений, которые не были выбраны для построения конкретного дерева. После того, как мы построили наше дерево с помощью n наблюдений, мы можем проверить каждый оставшийся $x_i$ и в итоге вычислить среднюю ошибку прогнозирования на основе этого набора.\n",
    "\n",
    "Более того, мы можем вычислить оценку OOB для каждого дерева и взять среднее значение всех этих оценок, чтобы получить оценку точности работы нашего случайного леса. По сути, это перекрестная проверка с исключением (leave-one-out). Это даст нам оценку точности нашей модели без необходимости формального тестирования ее на новых данных.\n",
    "\n",
    "В sklearn oob score можно использовать вместо проверки на тестовом множестве"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# fit standart rf\n",
    "print(\"Train oob score is: \", model.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Bias-variance\n",
    "Напомню, что ошибка модели (на которую мы можем повлиять) состоит из смещения и разброса. До этого мы предполагали (и могли показать теоретически), что случайный лес позволяет уменьшить разброс/дисперсию.\n",
    "Вспомним, как мы раньше оценивали bias-variance составляющие. Проверим, действительно ли случайный лес ведет себя так, как мы предполагали."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "# get decombosed error (from introduction notebook)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "И для целого леса"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# get decombosed error for random forest (from introduction notebook)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Число деревьев\n",
    "Увеличение числа элементарных моделей в ансамбле не меняет смещения и уменьшает дисперсию. Вопрос. Почему бы не использовать всегда огромное число деревьев?\n",
    "Мы можем даже посмотреть, как меняются оценки ошибок при добавлении новых деревьев. Заодно сравним разные способы ограничения количества признаков."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from collections import OrderedDict\n",
    "\n",
    "def get_score_plots(X_train, y_train, oob=True):\n",
    "    # NOTE: Setting the `warm_start` construction parameter to `True` disables\n",
    "    # support for parallelized ensembles but is necessary for tracking the OOB\n",
    "    # error trajectory during training.\n",
    "    params = dict(warm_start=True, oob_score=oob,random_state=SEED)\n",
    "    ensemble_clfs = [\n",
    "        (\n",
    "            \"RandomForestClassifier, max_features='sqrt'\",\n",
    "            RandomForestClassifier(max_features=\"sqrt\", **params),\n",
    "        ),\n",
    "        (\n",
    "            \"RandomForestClassifier, max_features='log2'\",\n",
    "            RandomForestClassifier(max_features=\"log2\", **params),\n",
    "        ),\n",
    "        (\n",
    "            \"RandomForestClassifier, max_features=None\",\n",
    "            RandomForestClassifier(max_features=None,**params),\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    error_rate = OrderedDict((label, []) for label, _ in ensemble_clfs)\n",
    "\n",
    "    # Range of `n_estimators` values to explore.\n",
    "    min_estimators = 20\n",
    "    max_estimators = 150\n",
    "\n",
    "    for label, clf in ensemble_clfs:\n",
    "        for i in range(min_estimators, max_estimators + 1, 5):\n",
    "            clf.set_params(n_estimators=i)\n",
    "            error = # fit classifier and compute error rate (1 - error)\n",
    "            error_rate[label].append((i, error))\n",
    "    # Generate the \"OOB error rate\" vs. \"n_estimators\" plot.\n",
    "    for label, clf_err in error_rate.items():\n",
    "        xs, ys = zip(*clf_err)\n",
    "        plt.plot(xs, ys, label=label)\n",
    "\n",
    "    plt.xlim(min_estimators, max_estimators)\n",
    "    plt.xlabel(\"n_estimators\")\n",
    "    y_label_pre = \"OOB\" if oob else \"Test\"\n",
    "    plt.ylabel(y_label_pre +\" error rate\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_score_plots(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_score_plots(X_train, y_train, oob=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "А что с нашим случайным лесом?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_our_plots(X_train, y_train, oob=True):\n",
    "    clf = RandomForest(random_state=SEED)\n",
    "    error_rate = []\n",
    "    # Range of `n_estimators` values to explore.\n",
    "    min_estimators = 20\n",
    "    max_estimators = 150\n",
    "\n",
    "    # your code. get values and generate the \"error rate\" vs. \"n_estimators\" plot.\n",
    "\n",
    "    xs, ys = zip(*error_rate)\n",
    "    plt.plot(xs, ys, label=\"Our random forest\")\n",
    "\n",
    "    plt.xlim(min_estimators, max_estimators)\n",
    "    plt.xlabel(\"n_estimators\")\n",
    "    y_label_pre = \"OOB\" if oob else \"Test\"\n",
    "    plt.ylabel(y_label_pre +\" error rate\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_our_plots(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Какая должна быть глубина деревьев в случайном лесу?\n",
    "Разброс уменьшается с помощью бэггинга. На смещение бэггинг не влияет, а хочется, чтобы у леса оно было небольшим. Поэтому смещение должно быть небольшим у самих деревьев, из которых строится ансамбль. У неглубоких деревьев малое число параметров, поэтому они могут запомнить самые простые статистики. К каким значениям смещения и дисперсии это приводит?\n",
    "И какой глубины все же выбирать деревья?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_error_dec(clf_dt, depth: int = 2):\n",
    "    # your code. decompose error\n",
    "    print(\"Depth = \", depth)\n",
    "    print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "    print('Average bias: %.3f' % avg_bias)\n",
    "    print('Average variance: %.3f' % avg_var)\n",
    "    print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred))\n",
    "get_error_dec(depth=2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# prepare and fit decision tree\n",
    "get_error_dec(depth=8)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# prepare and fit random forest. get error decomposition\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# if we have time, prepare plotsof bias-variance for different depths and numbers of trees"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Границы разбиения\n",
    "Рассмотрим также и границы принятия решений. То, как они будут выглядеть, становится довольно тривиальным вопросом, однако все равно построим их, чтобы полностью прочуствовать то, как работает RandomForest."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# copy the plotting code from previous practice"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# copy the plotting code from previous practice"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# copy the plotting code from previous practice\n",
    "plot_boundary(classifier, data=X_train_pca, features=features, y=y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features = [\"x1\", \"x2\"]\n",
    "classifier = # random forest\n",
    "plot_boundary(classifier, data=X_train_pca, features=features, y=y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# you can plot decision boundary for bagging classifier too."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bagging для линейных моделей.\n",
    "Если останется время, давайте рассмотрим и другое семейство моделей в качестве базовых. Вопрос. Как будет выглядеть предсказание для такого случая?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# what is the decision boundary of linear models ensemble?"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "ml",
   "language": "python",
   "display_name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
