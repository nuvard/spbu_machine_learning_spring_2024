{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import make_circles, make_blobs, make_classification, make_moons\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "\n",
    "SEED = 314159\n",
    "TRAIN_TEST_SPLIT = 0.80\n",
    "\n",
    "data_path = \"D:\\data\\machine_learning\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Рассмотрим набор данных о качестве вина на основе различных химических показателей. Есть всего 6 значений качества, поэтому задачу проще всего решать классификацией."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path+'/'+\"winequality-red.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Несбалансированные данные\n",
    "Несбалансированные данные - это одна из наиболее распространенных проблем, с которой сталкиваются в машинном обучении. Они возникают, когда классы, которые мы пытаемся предсказать, представлены неравномерно. Другими словами, один класс имеет гораздо меньше примеров, чем другой, что создает дисбаланс в распределении данных.\n",
    "Деревья решений очень уязвимы перед дисбалансом классов, так как используют вероятности в критериях разбиения."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = df.drop('quality', axis=1)\n",
    "y = df['quality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Train score is: \", model.score(X_train, y_train))\n",
    "print(\"Test score is: \", model.score(X_test, y_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Метрики\n",
    "Так как данные несбалансированные, уместно ли использовать встроенное значение score для оценки модели? На самом деле, и да и нет, так как score возвращает усредненную точность по классам. Однако еще более информатиными будут F1-мера и другие более подробные оценки.\n",
    "Формула Precision:\n",
    "\\begin{equation}\n",
    "\\text{Precision} = \\frac{\\text{TP}}{ \\text{TP} + \\text{FP} }\n",
    "\\end{equation}\n",
    "Precision наиболее полезна, если цена FP велика. Примеры такой задачи - детекция спама. В случае, если полезное письмо попадет в спам, юзер может потерять важную информацию, что нежелательно.\n",
    "Формула Recall:\n",
    "\\begin{equation}\n",
    "\\text{Recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}\n",
    "\\end{equation}\n",
    "Recall наиболее полезна, если цена FN велика. Она поможет, если нам необходимо найти всех больных пациентов, определить фрод и т.д.\n",
    "Вопрос: что отражают две эти метрики?\n",
    "\n",
    "\n",
    "Формула F1-метрики:\n",
    "\\begin{equation}\n",
    "\\text{F1} = \\frac{2 * \\text{TP}}{2 * \\text{TP} + \\text{FP} + \\text{FN}}\n",
    "\\end{equation}\n",
    "F1-метрика может быть выведена из precision и recall и позволяет найти баланс между ними. Вопрос - как она выводится?\n",
    "\n",
    "Существует и болеее общая оценка - $F_\\beta$. Она позволяет получить взвешенное среднее между precision и recall. Ее формулу дадим на занятии. Наиболее популярные параметры - 2 и 0.5.\n",
    "Тут тоже есть особенности. Метрики бывают нескольких видов, в зависимости от того, как учитываются разные классы:\n",
    "- микро - метрики считаются глобально сразу по всем классам.\n",
    "- макро - вначале считаются для каждого класса, потом берется среднее\n",
    "- взвешенные по классам - вначале считаются для каждого класса, потом берется среднее, взвешенное по поддержке\n",
    "\n",
    "Вопрос: какой способ вычисления лучше всего выбрать при дисбалансе классов? Покажите на примере."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(\"Train f1-score is: \", f1_score(y_train, model.predict(X_train), average=\"micro\"))\n",
    "print(\"Test f1-score is: \", f1_score(y_test, model.predict(X_test), average=\"micro\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(\"Train f1-score is: \", f1_score(y_train, model.predict(X_train), average=\"macro\"))\n",
    "print(\"Test f1-score is: \", f1_score(y_test, model.predict(X_test), average=\"macro\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(model, X_test, y_test)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Давайте руками рассмотрим, как оценивается точность и почему нам сложно получить адекватную оценку при сильном дисбалансе."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(columns=['label', 'TP', 'TN', 'FP', 'FN', 'support', 'accuracy', 'precision', 'recall'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.utils import compute_class_weight\n",
    "classes = np.unique(y_train)\n",
    "classes.sort()\n",
    "print(classes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for class_id in classes:\n",
    "    class_stats = {}\n",
    "    # your code\n",
    "    metrics_df = pd.concat([metrics_df, pd.DataFrame(class_stats, index=[0])], ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imbalanced learning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Как заставить модель учиться так, чтобы учитывать все классы? Самое простое - задать вес класса."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class_weights = # your code\n",
    "model = DecisionTreeClassifier(class_weight={classes[i]: w for i, w in enumerate(class_weights)})\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Train score is: \", model.score(X_train, y_train))\n",
    "print(\"Test score is: \", model.score(X_test, y_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Выведем, как изменились предсказания модели."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create new dataframe with metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Также посмотрим, насколько чувствительна к дисбалансу другая модель - LogisticRegression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logreg = # make pipeline of Scaler and Logreg\n",
    "logreg.fit(X_train, y_train)\n",
    "print(\"Naive train score is: \", logreg.score(X_train, y_train))\n",
    "print(\"Naive test score is: \", logreg.score(X_test, y_test))\n",
    "print(\"Classes\", logreg.classes_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logreg = # make pipeline of Scaler and Logreg with class weights\n",
    "logreg.fit(X_train, y_train)\n",
    "print(\"Balanced train score is: \", logreg.score(X_train, y_train))\n",
    "print(\"Balanced test score is: \", logreg.score(X_test, y_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "То же самое можно сделать с использованием итеративного линейного классификатора. Используем для этого SGDClassifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "logreg = # make pipeline of Scaler and SGDClassifier without class weights\n",
    "logreg.fit(X_train, y_train)\n",
    "print(\"Naive train score is: \", logreg.score(X_train, y_train))\n",
    "print(\"Naive test score is: \", logreg.score(X_test, y_test))\n",
    "print(\"Naive test f1-score is: \", f1_score(y_test, y_pred=logreg.predict(X_test), average=\"macro\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logreg = # make pipeline of Scaler and SGDClassifier with class weights\n",
    "logreg.fit(X_train, y_train)\n",
    "print(\"Balanced train score is: \", logreg.score(X_train, y_train))\n",
    "print(\"Balanced test score is: \", logreg.score(X_test, y_test))\n",
    "print(\"Balanced test f1-score is: \", f1_score(y_test, y_pred=logreg.predict(X_test), average=\"macro\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Как видно, балансировка не всегда одинаково полезна. Однако мы можем попробовать воспользоваться дополнительными методами для обучения нашего дерева. Это будет андер- и оверсемплинг (балансировка датасета). Самое простое - взять только небольшую, но сбалансированную часть обучающих данных для непосредственного обучения. Однако, для нашего случая это плохо подходит, так как данных довольно мало."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Еще раз вспомним, какие предсказания давало дерево решений для нашего набора"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(max_depth=5)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Train score is: \", model.score(X_train, y_train))\n",
    "print(\"Test score is: \", model.score(X_test, y_test))\n",
    "print(\"Test f1-score is: \", f1_score(y_test, y_pred=model.predict(X_test), average=\"macro\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=SEED, ) # choose your parameters\n",
    "X_res, y_res = ros.fit_resample(X_train, y_train)\n",
    "y_res.value_counts()\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth=5)\n",
    "model.fit(X_res, y_res)\n",
    "print(\"Train score is: \", model.score(X_res, y_res))\n",
    "print(\"Test score is: \", model.score(X_test, y_test))\n",
    "print(\"Test f1-score is: \", f1_score(y_test, y_pred=model.predict(X_test), average=\"macro\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SMOTE (Synthetic Minority Oversampling Technique):\n",
    "SMOTE позволяет расширить выборку, построив синтетические примеры на основе уже существующих. Это еще один вариант решения «проблем классового дисбаланса».\n",
    "\n",
    "Общая схема SMOTE:\n",
    "1) Для создания нового семпла используют пару признаков «соседних» примеров a  и b из миноритарного класса. Их находят, используя алгоритм ближайшего соседа KNN. В данном случае необходимо и достаточно для семпла a получить набор из k соседей, из которого в дальнейшем будет случайно выбран семпл b.\n",
    "2) Для создания нового семпла находят разность $d=X_b–X_a$, где $X_a,X_b$ – векторы признаков «соседних» примеров a  и b из миноритарного класса.\n",
    "3) Далее из $d$ путем его умножения на случайное число в интервале (0,1)  получают $d'$.\n",
    "4) Вектор признаков нового примера вычисляется путем сложения Xa и $d'$.\n",
    "\n",
    "Вопрос: сколько соседей выбирать? И сколько соседей стоит использовать для каждой узловой точки?\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=SEED) # choose your parameters\n",
    "X_res, y_res = smote.fit_resample(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_res.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=SEED) # choose your parameters\n",
    "X_res, y_res = smote.fit_resample(X_train, y_train)\n",
    "y_res.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(max_depth=5)\n",
    "model.fit(X_res, y_res)\n",
    "print(\"Train score is: \", model.score(X_res, y_res))\n",
    "print(\"Test score is: \", model.score(X_test, y_test))\n",
    "print(\"Test f1-score is: \", f1_score(y_test, y_pred=model.predict(X_test), average=\"macro\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=SEED) # choose your parameters\n",
    "X_res, y_res = smote.fit_resample(X_train, y_train)\n",
    "y_res.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(max_depth=5)\n",
    "model.fit(X_res, y_res)\n",
    "print(\"Train score is: \", model.score(X_res, y_res))\n",
    "print(\"Test score is: \", model.score(X_test, y_test))\n",
    "print(\"Test f1-score is: \", f1_score(y_test, y_pred=model.predict(X_test), average=\"macro\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Также мы можем получить более подробный отчет по точности модели."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from imblearn.metrics import classification_report_imbalanced"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(classification_report_imbalanced(y_test, model.predict(X_test)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Рассмотрим также поведение разных алгоритмов на синтетических данных."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_gen, y_gen = make_classification(n_samples=5000, n_features=2, n_informative=2,\n",
    "                           n_redundant=0, n_repeated=0, n_classes=3,\n",
    "                           n_clusters_per_class=1,\n",
    "                           weights=[0.01, 0.05, 0.94],\n",
    "                           class_sep=0.8, random_state=SEED)\n",
    "X_train, X_test, y_train, y_test = # train test split\n",
    "\n",
    "ros = RandomOverSampler(random_state=SEED)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Choosing the first 2 columns for the plot\n",
    "\n",
    "def get_decision_boundary(X_train, y_train, features, model=\"logistic\"):\n",
    "    # Creating and fitting the tree classifier\n",
    "    if model == \"logistic\":\n",
    "        classifier = # your code\n",
    "    else:\n",
    "        classifier = # your code\n",
    "    # Plotting the tree boundaries\n",
    "    disp = # your code\n",
    "\n",
    "    # Plotting the data points\n",
    "    # your code\n",
    "\n",
    "    plt.title(f\"Decision surface for {classifier.__class__.__name__} trained on {features[0]} and {features[1]}\")\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_decision_boundary(X_train, y_train, features = ['x1', 'x2' ])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_decision_boundary(X_resampled, y_resampled, features = ['x1', 'x2' ])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=SEED, k_neighbors=4)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "get_decision_boundary(X_resampled, y_resampled, features = ['x1', 'x2' ])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Введем еще один метод оверсемплинга - AdaSYN (Adaptive Synthetic). Этот алгоритм, в отличие от ресэмплинга и SMOTE позволяет сгенерировать более \"сложные\" примеры.\n",
    "Этот алгоритм работает следующим образом:\n",
    "1) Рассчитывается отношение миноритарного и мажоритарного класса: $d = m_s / m_l $\n",
    "2) Определяется, сколько элементов необходимо нагенерировать: $G = (m_l - m_s) * \\beta $. $\\beta $ - параметр балансировки\n",
    "3) Для каждого семпла из миноритарного класса находятся k соседей. После чего ему присваивается вес $r_i = num_major_neighbours / k $.\n",
    "4) $r_i$ нормализуются так, чтобы их сумма равнялсь 1: $ {r_i}' =  \\frac {r_i} {\\sum{r_j}$\n",
    "5) Для каждого семпла определяется число сгененрированных примеров.  $G_i = G * {r_i}' $. Вопрос: в каких областях будет генерироваться больше примеров?\n",
    "6) Далее для каждого примера и его соседей генерируется синтетический пример, как в SMOTE. Также может быть использована добавка белого шума.\n",
    "\n",
    "Вопрос: какие минусы у SMOTE и AdaSYN по отношению друг к другу?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "smote = ADASYN(random_state=SEED) # your parameters\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "get_decision_boundary(X_resampled, y_resampled, features = ['x1', 'x2' ])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "На графике сразу видно, когда AdaSYN  может помешать хорошей генерации. Как видно, так как AdaSYN концентрирует сгенерированные примеры у границ классов, тогда как SMOTE может \"соединять\" и примеры в центральной части класса, то он может быть более удачным методом. К тому же, сущестуют различные вариации SNOTE, которые могут давать хороший рещультат в такой постановке."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "smote = BorderlineSMOTE(random_state=SEED) # your parameters\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "get_decision_boundary(X_resampled, y_resampled, features = ['x1', 'x2' ])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Вопрос: какие можно еще придумать более \"умные\" варианты оверсемплинга на основе CMOTE?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Уменьшение выборки (андерсемплинг)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prototype generation\n",
    "Методы Prototype generation (создания прототипов) позволяют сократить количество объектов в целевых классах, но остальные объектов генерируются, а не выбираются, из исходного набора.\n",
    "ClusterCentroids использует для этого KMeans."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "sampler = ClusterCentroids(random_state=SEED, estimator=# your parameters)\n",
    "X_resampled, y_resampled = sampler.fit_resample(X_train, y_train)\n",
    "get_decision_boundary(X_resampled, y_resampled, features = ['x1', 'x2' ])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import ClusterCentroids\n",
    "sampler = ClusterCentroids(random_state=SEED, estimator=# your parameters)\n",
    "X_resampled, y_resampled = sampler.fit_resample(X_train, y_train)\n",
    "get_decision_boundary(X_resampled, y_resampled, features = ['x1', 'x2' ])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prototype selection\n",
    "Алгоритмы Prototype selection (выбора прототипов) можно разделить на две группы: (i) методы контролируемой недостаточной выборки и (ii) методы очистки недостаточной выборки.\n",
    "\n",
    "Методы контролируемой недостаточной выборки сокращают количество примеров в мажоритарных классах до произвольного размера, указанного пользователем. Обычно они сводят количество наблюдений к размеру миноритарного класса(ов).\n",
    "К ним относятся: Random UnderSampling, NearMiss\n",
    "Напротив, методы очистки недостаточной выборки «очищают» пространство признаков, удаляя либо «зашумленные», либо «слишком легко классифицируемые» наблюдения, в зависимости от метода. Окончательное количество наблюдений в каждом классе зависит от метода очистки и не может быть указано пользователем.\n",
    "К ним относится, например, метод связей Томека.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Наиболее простой метод - RandomUnderSampler - просто выкидывает семплы случайным образом."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_resampled, y_resampled = sampler.fit_resample(X_train, y_train)\n",
    "get_decision_boundary(X_resampled, y_resampled, features = ['x1', 'x2' ])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Попробуйте реализовать такой семплер вручную:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# your code"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "NearMiss добавляет некоторые эвристики для выбора семплов. Так, он может выбирать для удаления примеры, ближайшие к миноритарном классу, примеры, среднее расстояние у которых до наиболее дальних примеров из миноритарного класса наименьшее."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# you can add some figures with nearmiss undersampling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Связь Томека существует, когда два примера из разных классов являются ближайшими соседями друг к другу. Алгоритм связей Томека детектирует такие связи и удаляет пример из мажоритарного класса. Основная идея заключается в том, что связи Томека зашумлены или наблюдения трудно классифицировать, и поэтому они не помогут алгоритму найти подходящую границу разделения.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# youк сode"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Edited nearest neighbours - для примеров из миноритарного класса находит k ближайших соседей и удаляет все семплы из мажоритарных классов, попавшие в эту окрестность."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# your code"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
