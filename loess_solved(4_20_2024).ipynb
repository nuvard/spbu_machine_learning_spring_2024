{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import (\n",
    "    HuberRegressor,\n",
    "    LinearRegression,\n",
    "    RANSACRegressor,\n",
    "    TheilSenRegressor,\n",
    ")\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from scipy.linalg import qr, pinv\n",
    "from scipy.linalg import solve_triangular\n",
    "\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# LOESS\n",
    "Рассмотрим обыкновенную линейную регрессию. ЕЕ формула:\n",
    "\\begin{equation}\n",
    "y_i = f(x_i) + \\epsilon_i,\n",
    "\\end{equation}\n",
    "где\n",
    "\\begin{equation}\n",
    "f(x_i) = \\beta_0 + \\beta_1 \\cdot x_i\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Однако рассмотрим данные следующего вида:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-15, 15, 300)\n",
    "y = np.sin(x) + np.random.normal(0, 0.2, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=x, y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Попробуем обучить модель линейной модели на этих данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model = LinearRegression().fit(x.reshape(-1, 1),y)\n",
    "preds = model.predict(x.reshape(-1, 1))\n",
    "sns.scatterplot(x=x, y=y)\n",
    "sns.lineplot(x=x, y=preds, color=\"lightgreen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Кажется, что линейная модель никак не может выявить зависимость в данных. Одно из возможных решений - полиномиальная регрессия. Как думаете, какая степень полинома понадобится?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline( PolynomialFeatures(degree=11), LinearRegression())\n",
    "pipe.fit(x.reshape(-1, 1),y)\n",
    "preds = pipe.predict(x.reshape(-1, 1))\n",
    "sns.scatterplot(x=x, y=y)\n",
    "sns.lineplot(x=x, y=preds, color=\"lightgreen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Кажется, что для таких данных построить единую модель будет чрезвычайно сложно. Как можно решить такую проблему? Одно из решений - каким-то образом взвесить семплы, чтобы семплы ближе к переломам были более важны."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline( PolynomialFeatures(degree=11), LinearRegression())\n",
    "pipe.fit(x.reshape(-1, 1), y,  linearregression__sample_weight=abs(x))\n",
    "preds = pipe.predict(x.reshape(-1, 1))\n",
    "sns.scatterplot(x=x, y=y)\n",
    "sns.lineplot(x=x, y=preds, color=\"lightgreen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Выглядит уже ближе. Однако как бы нам сделать процесс взвешивания автоматическим? Рассмотрим модель взвешенной регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "\\begin{equation}\n",
    "f(x_i) = w_i(x_0) \\cdot [\\beta_0 + \\beta_1 \\cdot x_i + \\beta_2 \\cdot x_i^2 + \\dots]\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "1. Обозначим через $x_i$ набор n значений для конкретной переменной и пусть $y_i$ представляет соответствующие целевые значения.\n",
    "\n",
    "2. Найдем k ближайших точек к целевой точке $x_0$. Обозначим это множество $D_0$. (Важно учесть расстояния до них: $d_{i0}$).\n",
    "3. Найдем самое большое расстояние между этими k точками. Обозначим эту величину $\\delta(x_0)$\n",
    "\n",
    "4. Вычислим весовую функцию $w_i$ для каждого $x_i \\in D_0 $,  используя следующее соотношение:\n",
    "\\begin{equation}\n",
    "w_i(x_0) = W(\\frac{d_{i0}}{\\delta(x_0)})\n",
    "\\end{equation},\n",
    "где:\n",
    "\\begin{equation}\n",
    "    W(u) =\n",
    "    \\begin{cases}\n",
    "      (1 - u^3)^3, & 0 \\leq u < 1 \\\\\n",
    "      0, & \\text{otherwise}\n",
    "    \\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "5. Рассчитаем финальные веса регрессии $\\hat f(x_0)$\n",
    " для $x_0$, используя вычисленные веса:\n",
    "\\begin{equation}\n",
    "\\begin{align}\n",
    "\n",
    "WX\\hat \\beta &= Wy \\\\\n",
    "X'WX\\hat \\beta &= X'Wy \\\\\n",
    "\\hat \\beta &= (X'WX)^{-1}X'Wy\n",
    "\n",
    "\\end{align}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "LOESS сочетает в себе простоту линейной регрессии наименьших квадратов с гибкостью нелинейной регрессии. Как и в случае с ближайшими соседями, для LOESS нужны все обучающие данные каждый раз, когда мы хотим вычислить прогноз.\n",
    "\n",
    "Однако как определить, какие точки использовать для подгонки весов? За это отвечает параметр $bandwith$. Этот параметр играет роль, подобную параметру $\\gamma$ в сглаживании сплайнов: контролирует гибкость нелинейной подгонки. Чем меньше полоса пропускания, тем более локальным и волнистым будет сглаживание; очень большой диапазон приведет к глобальной подгонке данных с использованием всех обучающих наблюдений. Вопрос: В случае трикубического окна к какому решению будет стремиться подгон при устремлении $bandwith$ к бесконечности?\n",
    "\n",
    "Так, можно задать полосу пропускания (bandwith) как отступ по x, тогда в нее попадут все x, такие что: $| x_i - x| < h$. Какие минусы такого способа задания окна?\n",
    "\n",
    "Другой способ - задать ее числом соседей, которые будут использоваться для расчетов. Мы будем использовать именно его.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Реализуем метод локальной регрессии. Это придется делать в несколько этапов. Так, нам необходимо решить уравнение\n",
    "\\begin{equation}\n",
    "\\begin{align}\n",
    "\n",
    "WX\\hat \\beta &= Wy \\\\\n",
    "\n",
    "\\end{align}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def solve(x, y, W, deg: int = 1):\n",
    "\n",
    "    A = np.vander(x, N=1+deg) # |  X^2 |X | X^0 ... - we construct polynomial features from x\n",
    "\n",
    "    # x is horizontal, since we need to transpose it to get solution\n",
    "    V = np.matmul(np.matmul(A.T, W), A)  # (X^T W)^T X\n",
    "    Y = np.matmul(np.matmul(A.T, W), y)  # ( X^T W ) y\n",
    "    Q, R = qr(V)  # make triangular from matrix to get easier solution -> (X^T W)^T X = QR -> final equation: R beta = Q^T * ( X^T W ) y makes\n",
    "    p = solve_triangular(R, np.matmul(Q.T, Y)) # helps to solve equation with triangular left matrix\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "\n",
    "Напишем такую функциюб задающую нашу полосу пропускания и определяющие, кто туда попал:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_span(x: np.array, y: np.array, x_target: float, k: int) -> tuple[np.typing.NDArray, np.typing.NDArray, np.typing.NDArray]:\n",
    "    \"\"\" Returns distances, x in span and y in span.\n",
    "     x is all the x, x_targte - target x, k - number of neighbours to use\n",
    "     \"\"\"\n",
    "    # get list of distances\n",
    "    distance = abs(x - x_target)\n",
    "    # get sorted distances and corresponding indices (using, for example, np.sort + np.argsort)\n",
    "    sorted_dist = np.sort(distance)\n",
    "    ind = np.argsort(distance)\n",
    "    ind_span = ind[:k]\n",
    "    # we need to use x-s and y-s later in the code, so get them too\n",
    "    x_span = x[ind_span]\n",
    "    y_span = y[ind_span]\n",
    "    # which distance is the lowest?\n",
    "    delta_0 = sorted_dist[k-1]\n",
    "    # get normalized distances\n",
    "    u = distance[ind_span] / delta_0\n",
    "    return u, x_span, y_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def loess_tricub(x, y, k, deg):\n",
    "\n",
    "    y_hat = np.zeros(len(x))\n",
    "    x_space = np.zeros_like(x)\n",
    "\n",
    "    for i, x_target in enumerate(x):\n",
    "        u, x_span, y_span = get_span(x, y, x_target, k)\n",
    "        w = (1 - u**3)**3\n",
    "\n",
    "        W = np.diag(w)\n",
    "        p = solve(x_span, y_span, W, deg = deg)\n",
    "        y_hat[i] = np.polyval(p, x_target)\n",
    "        x_space[i] = x_target\n",
    "\n",
    "    return y_hat, x_space\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Построим график предсказаний. При этом проанимируем то, как строятся предсказания для разных k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "y_pred, x_pred = loess_tricub(x, y, k=5, deg=1)\n",
    "fig = plt.figure()\n",
    "sns.scatterplot(x=x, y=y, color ='skyblue')\n",
    "sns.lineplot(x=x_pred, y=y_pred, color ='lightgreen')\n",
    "print(\"error = \", mean_squared_error(y_true=y, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "y_pred, x_pred = loess_tricub(x, y, k=20, deg=1)\n",
    "fig = plt.figure()\n",
    "sns.scatterplot(x=x, y=y, color ='skyblue')\n",
    "sns.lineplot(x=x_pred, y=y_pred, color ='lightgreen')\n",
    "print(\"error = \", mean_squared_error(y_true=y, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Чем больше k, тем более сглаженным получается решение. Однако какое k выбрать? Как сделать так, чтобы для датасетов разного размера k было разумным? Можно, например, использовать пропорцию от размера датасета. Реализуем это."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_k_relative(alpha: float, n: int):\n",
    "    return int(np.ceil(alpha *n))\n",
    "\n",
    "def loess_tricub_alpha(x, y, alpha, deg):\n",
    "    k = get_k_relative(alpha=alpha, n=len(x))\n",
    "    y_hat = np.zeros(len(x))\n",
    "    x_space = np.zeros_like(x)\n",
    "\n",
    "    for i, x_target in enumerate(x):\n",
    "        u, x_span, y_span = get_span(x, y, x_target, k)\n",
    "        w = (1 - u**3)**3\n",
    "\n",
    "        W = np.diag(w)\n",
    "        p = solve(x_span, y_span, W, deg = deg)\n",
    "        y_hat[i] = np.polyval(p, x_target)\n",
    "        x_space[i] = x_target\n",
    "\n",
    "    return y_hat, x_space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "y_pred, x_pred = loess_tricub(x, y, k=20, deg=1)\n",
    "fig = plt.figure()\n",
    "sns.scatterplot(x=x, y=y, color ='skyblue')\n",
    "sns.lineplot(x=x_pred, y=y_pred, color ='lightgreen')\n",
    "print(\"error = \", mean_squared_error(y_true=y, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Можно ли использовать другие функции в качестве весовых? Да, например, воспользуемся колоковидным ядром:\n",
    "\\begin{equation}\n",
    "w^{(i)}  = \\exp \\left( - \\frac{(x^{(i)} - x)^2}{2 \\tau^2} \\right)\n",
    "\\end{equation}\n",
    "Параметр $\\tau$ контролирует, насколько быстро вес обучающего примера падает с увеличением расстояния до точки x\n",
    " и называется параметром _bandwidth_. Вопрос: Как меняется форма колококола при увеличении  $\\tau$?\n",
    "\n",
    "Вопрос: Является ли это ядро гауссовым?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def loess(x, y, kernel, alpha, deg, **kernel_params):\n",
    "    k = get_k_relative(alpha=alpha, n=len(x))\n",
    "    y_pred = np.zeros(len(x))\n",
    "    x_space = np.zeros_like(x)\n",
    "    for i, x_target in enumerate(x):\n",
    "        u, x_span, y_span, _ = get_span(x, y, x_target, k)\n",
    "        w = kernel(u, **kernel_params)\n",
    "        W = np.diag(w)\n",
    "        p = solve(x_span, y_span, W, deg = deg)\n",
    "        y_pred[i] = np.polyval(p, x_target)\n",
    "        x_space[i] = x_target\n",
    "    return x_space, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def tricub_kernel(dist):\n",
    "    return (1 - dist**3)**3\n",
    "\n",
    "def bell_kernel(dist, tau):\n",
    "    return  np.exp(- dist**2/(2*tau**2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x_est, y_est = loess(x, y, kernel=tricub_kernel, alpha=0.05, deg=1)\n",
    "sns.lineplot(x=x_est, y=y_est)\n",
    "sns.scatterplot(x=x, y=y, color ='skyblue')\n",
    "\n",
    "print(\"error = \", mean_squared_error(y_true=y, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "tau = 0.3\n",
    "x_est, y_est = loess(x, y, kernel=bell_kernel, alpha=0.05, deg=1, tau=tau)\n",
    "sns.lineplot(x=x_est, y=y_est)\n",
    "sns.scatterplot(x=x, y=y, color ='skyblue')\n",
    "\n",
    "print(\"error = \", mean_squared_error(y_true=y, y_pred=y_est))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Раз $tau$ регулирует, какой вклад будут давать дальние элементы, чего не было в обычном трикубическом ядре, нужен ли нам теперь параметр $\\alpha$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "tau = 0.01\n",
    "x_est, y_est = loess(x, y, kernel=bell_kernel, alpha=1., deg=1, tau=tau)\n",
    "sns.lineplot(x=x_est, y=y_est)\n",
    "sns.scatterplot(x=x, y=y, color ='skyblue')\n",
    "\n",
    "print(\"error = \", mean_squared_error(y_true=y, y_pred=y_est))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Если ошибки имеют симметричное распределение (с длинными хвостами) или есть выбросы, мы можем использовать более робастный LOESS.\n",
    "Определим остатки:\n",
    "\\begin{equation}\n",
    "r_i = y_i - f (x_i)\n",
    "\\end{equation}\n",
    "Используем базовое ядро, заданное биквадратной функцией:\n",
    "\\begin{equation}\n",
    "    B(u, b) =\n",
    "    \\begin{cases}\n",
    "      (1 - u^2)^2, & 0 \\leq u < 1 \\\\\n",
    "      0, & \\text{otherwise}\n",
    "    \\end{cases}\n",
    "\\end{equation}\n",
    "Пусть $m(r) = median(|r|)$. Дополнительные веса тогда:\n",
    "\\begin{equation}\n",
    "\\gamma_i = B(r_i / 6m)\n",
    "\\end{equation}\n",
    "\n",
    "Финальные веса принимают вид $\\tilde {w_i } = gamma_i * w_i.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def bicubic_kernel(dist):\n",
    "    mask = dist < 1.  \n",
    "    return ((1 - dist ** 2) ** 2) * mask\n",
    "\n",
    "def get_robust_weights(y, y_pred):\n",
    "    residuals = y - y_pred\n",
    "    s = np.median(np.abs(residuals))\n",
    "    multiplier = (np.abs(residuals) / (6.0 * s) ) # we clip to preserve final results bounds\n",
    "    multiplier = bicubic_kernel(multiplier)\n",
    "    return multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_span(x: np.array, y: np.array, x_target: float, k: int) -> tuple[np.typing.NDArray, np.typing.NDArray, np.typing.NDArray, np.typing.NDArray]:\n",
    "    \"\"\" Returns distances, x in span and y in span.\n",
    "     x is all the x, x_targte - target x, k - number of neighbours to use\n",
    "     \"\"\"\n",
    "    # get list of distances\n",
    "    distance = abs(x - x_target)\n",
    "    # get sorted distances and corresponding indices (using, for example, np.sort + np.argsort)\n",
    "    sorted_dist = np.sort(distance)\n",
    "    ind = np.argsort(distance)\n",
    "    ind_span = ind[:k]\n",
    "    # we need to use x-s and y-s later in the code, so get them too\n",
    "    x_span = x[ind_span]\n",
    "    y_span = y[ind_span]\n",
    "    # which distance is the lowest?\n",
    "    delta_0 = sorted_dist[k-1]\n",
    "    # get normalized distances\n",
    "    u = distance[ind_span] / delta_0\n",
    "    return u, x_span, y_span, ind_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def loess_robust(x, y, kernel, alpha, deg, iterations, **kernel_params):\n",
    "    k = get_k_relative(alpha=alpha, n=len(x))\n",
    "    y_pred = np.zeros(len(x))\n",
    "    x_space = np.zeros_like(x)\n",
    "    r_weights = np.ones(len(x))\n",
    "    for iter in range(iterations):\n",
    "        for i, x_target in enumerate(x):\n",
    "            u, x_span, y_span, ind_span = get_span(x, y, x_target, k)\n",
    "            w = kernel(u, **kernel_params) * r_weights[ind_span]\n",
    "            W = np.diag(w)\n",
    "            p = solve(x_span, y_span, W, deg = deg)\n",
    "            y_pred[i] = np.polyval(p, x_target)\n",
    "            x_space[i] = x_target\n",
    "        r_weights = get_robust_weights(y, y_pred)\n",
    "        print(r_weights)\n",
    "    return x_space, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-15, 15, 300)\n",
    "y = np.sin(x) + np.random.normal(0, 0.2, 300)\n",
    "y[5:10] -= 0.7\n",
    "y[45:50] += 1.1\n",
    "y[-30] += 1.\n",
    "x[-45:-40] -= 0.1\n",
    "\n",
    "x[45] += 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x_est_naive , y_est_naive = loess(x, y, kernel=bell_kernel, alpha=0.3, deg=1, tau=tau)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "tau = 0.4\n",
    "\n",
    "print('--')\n",
    "y_temp = y.copy()\n",
    "y_temp[0:100] += 0.2 * x[0:100]\n",
    "y_temp[100:] -= 0.2 * x[100:]\n",
    "\n",
    "x_est, y_est = loess_robust(x, y_temp, kernel=bell_kernel, alpha=0.8, deg=1, iterations=5, tau=tau)\n",
    "sns.lineplot(x=x_est, y=y_est, color=\"magenta\")\n",
    "print('--')\n",
    "\n",
    "sns.scatterplot(x=x, y=y_temp, color ='skyblue')\n",
    "\n",
    "print(\"error = \", mean_squared_error(y_true=y, y_pred=y_est))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Как видно, все ядра, которые мы использовали ранее, давали меньшие значения при увеличении расстояния. Однако есть ядро, которое использует равномерное распределение. Давайте его реализуем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "tau = 0.4\n",
    "\n",
    "print('--')\n",
    "x_est, y_est = loess_robust(x, y, kernel=bell_kernel, alpha=0.03, deg=1, iterations=6, tau=tau)\n",
    "sns.lineplot(x=x_est, y=y_est, color=\"magenta\")\n",
    "x_est, y_est = loess(x, y, kernel=bell_kernel, alpha=0.03, deg=1, tau=tau)\n",
    "sns.lineplot(x=x_est, y=y_est, color=\"green\")\n",
    "print('--')\n",
    "\n",
    "sns.scatterplot(x=x, y=y, color ='skyblue')\n",
    "\n",
    "print(\"error = \", mean_squared_error(y_true=y, y_pred=y_est))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Какому методу эквивалентно использование этого ядра?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data_path = \"D:\\data\\machine_learning\"\n",
    "data = pd.read_csv(f\"{data_path}/realestate.txt\", sep=\"\\t\")\n",
    "\n",
    "data = data[[\"SalePrice\", \"SqFeet\", \"Lot\"]]\n",
    "data = np.log(data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[[\"SqFeet\"]], data[\"SalePrice\"])\n",
    "\n",
    "model = LinearRegression().fit(X_train, y_train)\n",
    "preds = model.predict(X_train)\n",
    "loess_x, loess_y = loess_robust(X_train.values.astype(float).ravel(), y_train.values.astype(float).ravel(), kernel=bell_kernel, alpha=0.05, deg=2, iterations=5, tau=tau)\n",
    "loess_x_naive , loess_y_naive = loess(X_train.values.astype(float).ravel(), y_train.values.astype(float).ravel(), kernel=bell_kernel, alpha=0.05, deg=2, tau=tau)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "tau = 0.4\n",
    "\n",
    "print('--')\n",
    "sns.lineplot(x=loess_x, y=loess_y , color=\"magenta\")\n",
    "print('--')\n",
    "sns.lineplot(x=loess_x_naive, y= loess_y_naive , color ='skyblue')\n",
    "sns.lineplot(x=X_train.values.astype(float).ravel(), y= preds.ravel() , color ='lightgreen')\n",
    "sns.scatterplot(x=X_train.values.astype(float).ravel(), y=y_train.values.astype(float).ravel() , color ='skyblue')\n",
    "print(\"Linear Regression error: \", mean_squared_error(y_true=y_train.values.astype(float).ravel(), y_pred=preds))\n",
    "print(\"loess error = \", mean_squared_error(y_true=y_train.values.astype(float).ravel(), y_pred=loess_y_naive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
